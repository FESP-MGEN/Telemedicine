{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "#####################################################################################################\n",
    "# 4_Abstract classification\n",
    "#####################################################################################################\n",
    "#####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # File management\n",
    "import string # Character chain management\n",
    "import pandas # Import data into DataFrame  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split # Selection abstract for learning corpus  \n",
    "from sklearn.feature_extraction.text import CountVectorizer # Matrix construction for learning\n",
    "from sklearn.linear_model import LogisticRegression # Logistic regression\n",
    "from sklearn import metrics # Confusion matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer # For reverse function\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import stats\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the \"import and cleaning abstracts\" program\n",
    "%run \"C:\\\\Users\\\\....\\\\Program\\\\2_Import and cleaning abstracts.ipynb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised learning of the abstract corpus\n",
    "\n",
    "# Creation of the training sample (random_state = the seed of the random)\n",
    "article_vf_Train,article_vf_Test=train_test_split(articles_vf,train_size=0.2,random_state=1,stratify=articles_vf['Selection'])\n",
    "\n",
    "# Build the analyzer with new options: stop_words = 'english' and min_df = 20\n",
    "analyseurBis = CountVectorizer(ngram_range=(1,4), stop_words='english',binary=True, min_df=0.04)\n",
    "\n",
    "# Create the document term matrix\n",
    "XTrain_bis = analyseurBis.fit_transform(article_vf_Train['Abstract'])\n",
    "\n",
    "# With the tfidf transformation\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(XTrain_bis)\n",
    "X_train_tfidf.shape\n",
    "\n",
    "# Transform the matrix into a numpy matrix\n",
    "mdtTrainBis = XTrain_bis.toarray()\n",
    "mdtTrain_tfidf = X_train_tfidf.toarray()\n",
    "\n",
    "# Logistics with and without transformation tfidf\n",
    "modelLog = LogisticRegression()\n",
    "modelLog_tfidf = LogisticRegression()\n",
    "\n",
    "# Naive Bayesien with and without transformation tfidf\n",
    "modelNB=MultinomialNB()\n",
    "modelNB_tfidf=MultinomialNB()\n",
    "\n",
    "# Execution of models\n",
    "modelLog_tfidf.fit(mdtTrain_tfidf,article_vf_Train['Selection'])\n",
    "modelLog.fit(mdtTrainBis,article_vf_Train['Selection'])\n",
    "modelNB_tfidf.fit(mdtTrain_tfidf,article_vf_Train['Selection'])\n",
    "modelNB.fit(mdtTrainBis,article_vf_Train['Selection'])\n",
    "\n",
    "# Evaluation on the test sample\n",
    "mdtTestBis= analyseurBis.transform(article_vf_Test['Abstract'])\n",
    "\n",
    "# Predictions for abstract test data\n",
    "# Logistic\n",
    "predTestBis_Log = modelLog.predict(mdtTestBis)\n",
    "predTestBis_Log_tfidf= modelLog_tfidf.predict(mdtTestBis)\n",
    "# Naive Bayesien\n",
    "predTestBis_NB = modelNB.predict(mdtTestBis)\n",
    "predTestBis_NB_tfidf = modelNB_tfidf.predict(mdtTestBis)\n",
    "\n",
    "# Confusion matrices\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(article_vf_Test['Selection'],predTestBis_Log).ravel()\n",
    "mcTestBis_Log = metrics.confusion_matrix(article_vf_Test['Selection'],predTestBis_Log)\n",
    "mcTestBis_Log_tfidf = metrics.confusion_matrix(article_vf_Test['Selection'],predTestBis_Log_tfidf)\n",
    "mcTestBis_NB = metrics.confusion_matrix(article_vf_Test['Selection'],predTestBis_NB)\n",
    "mcTestBis_NB_tfidf  = metrics.confusion_matrix(article_vf_Test['Selection'],predTestBis_NB_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays of the different model outputs\n",
    "print('Logistic matrix without tf-idf:')\n",
    "print(mcTestBis_Log)   \n",
    "print()\n",
    "print('F1 Logistic without tf-idf:')\n",
    "print(f1_score(article_vf_Test['Selection'], predTestBis_Log, average='macro'))\n",
    "print(fbeta_score(article_vf_Test['Selection'], predTestBis_Log, beta=2))\n",
    "print()\n",
    "print('Logistic matrix with tf-idf:')\n",
    "print(mcTestBis_Log_tfidf) \n",
    "print()\n",
    "print('F1 logistic with tf-idf:')\n",
    "print(f1_score(article_vf_Test['Selection'], predTestBis_Log_tfidf, average='macro'))\n",
    "print(fbeta_score(article_vf_Test['Selection'], predTestBis_Log_tfidf, beta=2))\n",
    "print()\n",
    "print('Naive Bayesian matrix without tf-idf:')\n",
    "print(mcTestBis_NB)\n",
    "print()\n",
    "print('F1 Naive Bayesian without tf-idf:')\n",
    "print(f1_score(article_vf_Test['Selection'], predTestBis_NB, average='macro'))\n",
    "print(fbeta_score(article_vf_Test['Selection'], predTestBis_NB, beta=2))\n",
    "print()\n",
    "print('Naive Bayesian matrix with tf-idf:')\n",
    "print(mcTestBis_NB_tfidf)\n",
    "print()\n",
    "print('F1 Naive Bayesian with tf-idf: ')\n",
    "print(f1_score(article_vf_Test['Selection'], predTestBis_NB_tfidf, average='macro'))\n",
    "print(fbeta_score(article_vf_Test['Selection'], predTestBis_NB_tfidf, beta=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export of the words used in the analysis and their associated regression coefficient\n",
    "# We transpose the array of coeff and we transform it into a dataframe\n",
    "coef_tr=numpy.transpose(modelLog_tfidf.coef_)\n",
    "\n",
    "# Export to Excel\n",
    "with pd.ExcelWriter(r'C:\\\\Users\\\\....\\\\Result\\\\coefficients_log.xlsx') as writer:  \n",
    "    pandas.DataFrame(analyseurBis.get_feature_names()).to_excel(writer)\n",
    "    pandas.DataFrame(coef_tr).to_excel(writer, sheet_name=\"Log avec tfidf 0.2\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "#    Automation of the program to test different parameters\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters which may vary: sample size, root, beta for F1\n",
    "\n",
    "\n",
    "# We vary the size of the sample then the root and for each sample the beta\n",
    "\n",
    "# Initialization of lists\n",
    "f05=[]\n",
    "f1=[]\n",
    "f2=[]\n",
    "f3=[]\n",
    "f5=[]\n",
    "f100=[]\n",
    "f1000=[]  \n",
    "vrai_neg=[]\n",
    "faux_neg=[]\n",
    "vrai_pos=[]\n",
    "faux_pos=[]\n",
    "\n",
    "# We focus on the model that seems best to us: logistics with tfidf\n",
    "\n",
    "# Creation of a list with all the desired sample sizes\n",
    "echantillon=[0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "for i in echantillon:\n",
    "\n",
    "    for r in range(1,100):\n",
    "        # Creation of the training sample (random_state = the seed of the random)\n",
    "        article_vf_Train,article_vf_Test=train_test_split(articles_vf,train_size=i,random_state=r,stratify=articles_vf['Selection'])\n",
    "\n",
    "        # Build the analyzer with new options: stop_words = 'english' and min_df = 20\n",
    "        analyseurBis = CountVectorizer(ngram_range=(1,4), stop_words='english',binary=True, min_df=0.04)\n",
    "        \n",
    "        # Create the document term matrix\n",
    "        XTrain_bis = analyseurBis.fit_transform(article_vf_Train['Abstract'])\n",
    "       \n",
    "        # The matrix with the terms of the abstracts\n",
    "        mdtTrainBis = XTrain_bis.toarray()\n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "        X_train_tfidf = tfidf_transformer.fit_transform(XTrain_bis)\n",
    "        X_train_tfidf.shape\n",
    "        \n",
    "        # Transform the matrix into a numpy matrix\n",
    "        mdtTrain_tfidf = X_train_tfidf.toarray()\n",
    "        \n",
    "        # The matrix with the terms of the abstracts\n",
    "        mdtTrainBis = XTrain_bis.toarray()\n",
    "        \n",
    "    # Initialize the object\n",
    "        # Logistic\n",
    "        modelLog_tfidf = LogisticRegression()\n",
    "        \n",
    "        # Model execution\n",
    "        modelLog_tfidf.fit(mdtTrain_tfidf,article_vf_Train['Selection'])\n",
    "        \n",
    "        # Evaluation on the test sample\n",
    "        mdtTestBis= analyseurBis.transform(article_vf_Test['Abstract'])\n",
    "        \n",
    "    # Prédiction pour les données des abstracts test\n",
    "        # Logistic\n",
    "        predTestBis_Log_tfidf= modelLog_tfidf.predict(mdtTestBis)\n",
    "           \n",
    "        # Confusion matrices\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix(article_vf_Test['Selection'],predTestBis_Log_tfidf).ravel()\n",
    "        \n",
    "        vrai_neg.append(tn)\n",
    "        faux_pos.append(fp)\n",
    "        faux_neg.append(fn)\n",
    "        vrai_pos.append(tp)\n",
    "    \n",
    "        f05.append(fbeta_score(article_vf_Test['Selection'], predTestBis_Log_tfidf, beta=0.5))\n",
    "        f1.append(fbeta_score(article_vf_Test['Selection'], predTestBis_Log_tfidf, beta=1))\n",
    "        f2.append(fbeta_score(article_vf_Test['Selection'], predTestBis_Log_tfidf, beta=2))\n",
    "        f3.append(fbeta_score(article_vf_Test['Selection'], predTestBis_Log_tfidf, beta=3))\n",
    "        f5.append(fbeta_score(article_vf_Test['Selection'], predTestBis_Log_tfidf, beta=5))\n",
    "        f100.append(fbeta_score(article_vf_Test['Selection'], predTestBis_Log_tfidf, beta=100))\n",
    "        f1000.append(fbeta_score(article_vf_Test['Selection'], predTestBis_Log_tfidf, beta=1000))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df05 = pd.DataFrame(np.array(f05).reshape(9,99))\n",
    "df05t=df05.T\n",
    "\n",
    "df1 = pd.DataFrame(np.array(f1).reshape(9,99))\n",
    "df1t=df1.T\n",
    "\n",
    "df3 = pd.DataFrame(np.array(f3).reshape(9,99))\n",
    "df3t=df3.T\n",
    "\n",
    "df100 = pd.DataFrame(np.array(f100).reshape(9,99))\n",
    "df100t=df100.T\n",
    "\n",
    "df2 = pd.DataFrame(np.array(f2).reshape(9,99))\n",
    "df2t=df2.T\n",
    "\n",
    "df5 = pd.DataFrame(np.array(f5).reshape(9,99))\n",
    "df5t=df5.T \n",
    "\n",
    "df1000 = pd.DataFrame(np.array(f1000).reshape(9,99))\n",
    "df1000t=df1000.T\n",
    "\n",
    "# Export to Excel\n",
    "with pd.ExcelWriter(r'C:\\\\Users\\\\....\\\\Result\\\\beta_and_ci.xlsx') as writer:  \n",
    "    df05t.to_excel(writer, sheet_name=\"beta=0.5\")\n",
    "    df1t.to_excel(writer, sheet_name=\"beta=1\")\n",
    "    df2t.to_excel(writer, sheet_name=\"beta=2\")\n",
    "    df3t.to_excel(writer, sheet_name=\"beta=3\")\n",
    "    df5t.to_excel(writer, sheet_name=\"beta=5\")\n",
    "    df100t.to_excel(writer, sheet_name=\"beta=100\")\n",
    "    df1000t.to_excel(writer, sheet_name=\"beta=1000\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vp=pd.DataFrame(np.array(vrai_pos).reshape(9,99))\n",
    "df_vpt=df_vp.T\n",
    "df_vn=pd.DataFrame(np.array(vrai_neg).reshape(9,99))\n",
    "df_vnt=df_vn.T\n",
    "df_fn=pd.DataFrame(np.array(faux_neg).reshape(9,99))\n",
    "df_fnt=df_fn.T\n",
    "df_fp=pd.DataFrame(np.array(faux_pos).reshape(9,99))\n",
    "df_fpt=df_fp.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(r'C:\\\\Users\\\\....\\\\Result\\\\result_matrix.xlsx') as writer:  \n",
    "    df_vpt.to_excel(writer, sheet_name=\"True positive\")\n",
    "    df_vnt.to_excel(writer, sheet_name=\"True negative\")\n",
    "    df_fnt.to_excel(writer, sheet_name=\"False negative\")\n",
    "    df_fpt.to_excel(writer, sheet_name=\"False positive\")\n",
    "\n",
    "# Calculation of means and standard error\n",
    "meanvp = df_vpt.mean()\n",
    "stdvp = df_vpt.std()\n",
    "meanvn = df_vnt.mean()\n",
    "stdvn = df_vnt.std()\n",
    "meanfn = df_fnt.mean()\n",
    "stdfn = df_fnt.std()\n",
    "meanfp = df_fpt.mean()\n",
    "stdfp = df_fpt.std()\n",
    "\n",
    "# Calculation of CI\n",
    "conf_intvp = stats.norm.interval(0.95, loc=meanvp, scale=stdvp/sqrt(99))\n",
    "conf_intvn = stats.norm.interval(0.95, loc=meanvn, scale=stdvn/sqrt(99))\n",
    "conf_intfn = stats.norm.interval(0.95, loc=meanfn, scale=stdfn/sqrt(99))\n",
    "conf_intfp = stats.norm.interval(0.95, loc=meanfp, scale=stdfp/sqrt(99))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of confidence intervals for the matrix of the selected model\n",
    "print(meanvn[3], end=' [')\n",
    "print(conf_intvn[0][3], end=' ; ')\n",
    "print(conf_intvn[1][3], end=']')\n",
    "print()\n",
    "\n",
    "print(meanfp[3], end=' [')\n",
    "print(conf_intfp[0][3], end=' ; ')\n",
    "print(conf_intfp[1][3], end=']')\n",
    "print()\n",
    "\n",
    "print(meanfn[3], end=' [')\n",
    "print(conf_intfn[0][3], end=' ; ')\n",
    "print(conf_intfn[1][3], end=']')\n",
    "print()\n",
    "\n",
    "print(meanvp[3], end=' [')\n",
    "print(conf_intvp[0][3], end=' ; ')\n",
    "print(conf_intvp[1][3], end=']')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of Excel file\n",
    "xl = pd.ExcelFile(\"C:\\\\Users\\\\....\\\\Result\\\\beta_and_ci.xlsx\")\n",
    "\n",
    "df05 = xl.parse(\"beta=0.5\")\n",
    "df1 = xl.parse(\"beta=1\")\n",
    "df2 = xl.parse(\"beta=2\")\n",
    "df3 = xl.parse(\"beta=3\")\n",
    "df5 = xl.parse(\"beta=5\")\n",
    "df100 = xl.parse(\"beta=100\")\n",
    "df1000 = xl.parse(\"beta=1000\")\n",
    "\n",
    "# Removal of unnecessary information\n",
    "del df05['Unnamed: 0']\n",
    "del df1['Unnamed: 0']\n",
    "del df2['Unnamed: 0'] \n",
    "del df3['Unnamed: 0']\n",
    "del df5['Unnamed: 0']\n",
    "del df100['Unnamed: 0']\n",
    "del df1000['Unnamed: 0']\n",
    "\n",
    "# Calculation of means and standard error\n",
    "meanf05 = df05.mean()\n",
    "stdf05 = df05.std()\n",
    "meanf1 = df1.mean()\n",
    "stdf1 = df1.std()\n",
    "meanf2 = df2.mean()\n",
    "stdf2 = df2.std()\n",
    "meanf3 = df3.mean()\n",
    "stdf3 = df3.std()\n",
    "meanf5 = df5.mean()\n",
    "stdf5 = df5.std()\n",
    "meanf100 = df100.mean()\n",
    "stdf100 = df100.std()\n",
    "meanf1000 = df1000.mean()\n",
    "stdf1000 = df1000.std()\n",
    "\n",
    "# Calculation of CI\n",
    "conf_intf05 = stats.norm.interval(0.95, loc=meanf05, scale=stdf05/sqrt(99))\n",
    "conf_intf1 = stats.norm.interval(0.95, loc=meanf1, scale=stdf1/sqrt(99))\n",
    "conf_intf2 = stats.norm.interval(0.95, loc=meanf2, scale=stdf2/sqrt(99))\n",
    "conf_intf3 = stats.norm.interval(0.95, loc=meanf3, scale=stdf3/sqrt(99))\n",
    "conf_intf5 = stats.norm.interval(0.95, loc=meanf5, scale=stdf5/sqrt(99))\n",
    "conf_intf100 = stats.norm.interval(0.95, loc=meanf100, scale=stdf100/sqrt(99))\n",
    "conf_intf1000 = stats.norm.interval(0.95, loc=meanf1000, scale=stdf1000/sqrt(99))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a list with all the desired sample sizes\n",
    "echantillon=[0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "# Creation of the X scale with the sample sizes\n",
    "x=np.asarray(echantillon)\n",
    "plt.figure(figsize=(10,6), dpi=100)\n",
    "\n",
    "# The y-axis represents percentages, we use the range 0.1 / 1\n",
    "plt.ylim(0.1,1.0)\n",
    "\n",
    "G1=plt.plot(x, meanf05, marker=\".\", color='#CD5C5C',linewidth=1, linestyle='-', label='Beta = 0.5')\n",
    "G1=plt.plot(x, conf_intf05[0], color='#CD5C5C', linewidth=0.5, linestyle=':')\n",
    "G1=plt.plot(x, conf_intf05[1], color='#CD5C5C', linewidth=0.5, linestyle=':')\n",
    "\n",
    "G1=plt.plot(x, meanf1, marker=\".\", color='#4682B4',linewidth=1, linestyle='-', label='Beta = 1')\n",
    "G1=plt.plot(x, conf_intf1[0], color='#4682B4', linewidth=0.5, linestyle=':')\n",
    "G1=plt.plot(x, conf_intf1[1], color='#4682B4', linewidth=0.5, linestyle=':')\n",
    "\n",
    "G1=plt.plot(x, meanf2, marker=\".\", color='#FF6347',linewidth=1, linestyle='-', label='Beta = 2')\n",
    "G1=plt.plot(x, conf_intf2[0], color='#FF6347', linewidth=0.5, linestyle=':')\n",
    "G1=plt.plot(x, conf_intf2[1], color='#FF6347', linewidth=0.5, linestyle=':')\n",
    "\n",
    "G1=plt.plot(x, meanf3, marker=\".\", color='#000080',linewidth=1, linestyle='-', label='Beta = 3')\n",
    "G1=plt.plot(x, conf_intf3[0], color='#000080', linewidth=0.5, linestyle=':')\n",
    "G1=plt.plot(x, conf_intf3[1], color='#000080', linewidth=0.5, linestyle=':')\n",
    "\n",
    "G1=plt.plot(x, meanf5, marker=\".\", color='#8B0000',linewidth=1, linestyle='-', label='Beta = 5')\n",
    "G1=plt.plot(x, conf_intf5[0], color='#8B0000', linewidth=0.5, linestyle=':')\n",
    "G1=plt.plot(x, conf_intf5[1], color='#8B0000', linewidth=0.5, linestyle=':')\n",
    "\n",
    "G1=plt.plot(x, meanf100, marker=\".\", color='#87CEFA',linewidth=1, linestyle='-', label='Beta = 100')\n",
    "G1=plt.plot(x, conf_intf100[0], color='#87CEFA', linewidth=0.5, linestyle=':')\n",
    "G1=plt.plot(x, conf_intf100[1], color='#87CEFA', linewidth=0.5, linestyle=':')\n",
    "\n",
    "G1=plt.legend(loc='upper left')\n",
    "\n",
    "# Print the plot\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "fig = G1.get_figure()\n",
    "fig.savefig(\"C:\\\\Users\\\\....\\\\Result\\\\Graph_Classification.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
